{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3e5bd0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import category_encoders as ce\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd69626c",
   "metadata": {},
   "source": [
    "#### Preparatory work\n",
    "1. get [datasets](https://staff.itee.uq.edu.au/marius/NIDS_datasets/#RA1).\n",
    "2. Download the NF-BoT-IoT NF-ToN-IoT NF-CSE-CIC-IDS2018-v2 NF-UNSW-NB15-v2 dataset csv file  and place it under the **datasets** folder"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## NF-CSE-CIC-IDS2018-v2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label\n",
      "0    16635567\n",
      "1     2258141\n",
      "Name: count, dtype: int64\n",
      "Attack\n",
      "Benign                      16635567\n",
      "DDOS attack-HOIC             1080858\n",
      "DoS attacks-Hulk              432648\n",
      "DDoS attacks-LOIC-HTTP        307300\n",
      "Bot                           143097\n",
      "Infilteration                 116361\n",
      "SSH-Bruteforce                 94979\n",
      "DoS attacks-GoldenEye          27723\n",
      "FTP-BruteForce                 25933\n",
      "DoS attacks-SlowHTTPTest       14116\n",
      "DoS attacks-Slowloris           9512\n",
      "Brute Force -Web                2143\n",
      "DDOS attack-LOIC-UDP            2112\n",
      "Brute Force -XSS                 927\n",
      "SQL Injection                    432\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "dataset_name = 'NF-CSE-CIC-IDS2018-v2'\n",
    "data = pd.read_csv( f'./datasets/{dataset_name}.csv')\n",
    "print(data['Label'].value_counts())\n",
    "print(data['Attack'].value_counts())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## NF-UNSW-NB15-v2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label\n",
      "0    2295222\n",
      "1      95053\n",
      "Name: count, dtype: int64\n",
      "Attack\n",
      "Benign            2295222\n",
      "Exploits            31551\n",
      "Fuzzers             22310\n",
      "Generic             16560\n",
      "Reconnaissance      12779\n",
      "DoS                  5794\n",
      "Analysis             2299\n",
      "Backdoor             2169\n",
      "Shellcode            1427\n",
      "Worms                 164\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "dataset_name = 'NF-UNSW-NB15-v2' # 'NF-ToN-IoT'\n",
    "data = pd.read_csv( f'./datasets/{dataset_name}.csv')\n",
    "print(data['Label'].value_counts())\n",
    "print(data['Attack'].value_counts())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10e5b496",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cnames = ['TCP_FLAGS','L7_PROTO','PROTOCOL']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "793aa0d6",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## NF-BoT-IoT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "156fe5ce",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 600100\n",
      "TCP_FLAGS 23\n",
      "L7_PROTO 89\n",
      "PROTOCOL 3\n",
      "Label\n",
      "1    586241\n",
      "0     13859\n",
      "Name: count, dtype: int64\n",
      "Attack\n",
      "Reconnaissance    470655\n",
      "DDoS               56844\n",
      "DoS                56833\n",
      "Benign             13859\n",
      "Theft               1909\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "dataset_name = 'NF-BoT-IoT' # 'NF-ToN-IoT'\n",
    "data = pd.read_csv( f'./datasets/{dataset_name}.csv')\n",
    "data['IPV4_SRC_FULL_ADDR'] = data['IPV4_SRC_ADDR'].astype(str) + ':' + data['L4_SRC_PORT'].astype(str)\n",
    "data['IPV4_DST_FULL_ADDR'] = data['IPV4_DST_ADDR'].astype(str) + ':' + data['L4_DST_PORT'].astype(str)\n",
    "print('Number of samples:', data.shape[0])\n",
    "for cname in cat_cnames:\n",
    "    print(cname, data[cname].nunique())\n",
    "print(data['Label'].value_counts())\n",
    "print(data['Attack'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41990dcd",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## NF-ToN-IoT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "55432d78",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 1379274\n",
      "TCP_FLAGS 24\n",
      "L7_PROTO 97\n",
      "PROTOCOL 5\n",
      "Label\n",
      "1    1108995\n",
      "0     270279\n",
      "Name: count, dtype: int64\n",
      "Attack\n",
      "injection     468539\n",
      "ddos          326345\n",
      "Benign        270279\n",
      "password      156299\n",
      "xss            99944\n",
      "scanning       21467\n",
      "dos            17717\n",
      "backdoor       17247\n",
      "mitm            1295\n",
      "ransomware       142\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "dataset_name = 'NF-ToN-IoT'\n",
    "data = pd.read_csv(f'datasets/{dataset_name}.csv')\n",
    "print('Number of samples:', data.shape[0])\n",
    "for cname in cat_cnames:\n",
    "    print(cname, data[cname].nunique())\n",
    "print(data['Label'].value_counts())\n",
    "print(data['Attack'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "537dccf0",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Discard values outside the range of values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def dropdata(df):\n",
    "    max_threshold = torch.finfo(torch.float32).max\n",
    "    min_threshold = torch.iinfo(torch.int32).min\n",
    "    # Find the index of the row that is less than the minimum threshold\n",
    "    src_to_dst_min_indices = df[df['SRC_TO_DST_SECOND_BYTES'] <= min_threshold].index\n",
    "    dst_to_src_min_indices = df[df['DST_TO_SRC_SECOND_BYTES'] <= min_threshold].index\n",
    "\n",
    "    # Find the index of the row that is greater than the maximum threshold\n",
    "    src_to_dst_max_indices = df[df['SRC_TO_DST_SECOND_BYTES'] >= max_threshold].index\n",
    "    dst_to_src_max_indices = df[df['DST_TO_SRC_SECOND_BYTES'] >= max_threshold].index\n",
    "\n",
    "    # Merge row indexes that exceed the threshold\n",
    "    indices_to_drop = (\n",
    "        src_to_dst_min_indices.union(dst_to_src_min_indices)\n",
    "        .union(src_to_dst_max_indices)\n",
    "        .union(dst_to_src_max_indices)\n",
    "    )\n",
    "\n",
    "    # Discard rows that exceed the threshold\n",
    "    df_cleaned = df.drop(indices_to_drop)\n",
    "    return df_cleaned\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Split data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c3b904cd",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_tvt(data, label_cname='Label', tvt_ratio=(0.6,0.2,0.2), seed=2024, verbose=False):\n",
    "    assert sum(tvt_ratio) == 1, \"Incorrect train/val/test ratio\"\n",
    "    df_tvt = data.copy()\n",
    "    tvt_cname = f'{label_cname}_tvt'\n",
    "    df_tvt[tvt_cname] = 'Other'\n",
    "    # get si\n",
    "    val_ratio = tvt_ratio[1]\n",
    "    test_ratio = tvt_ratio[2]\n",
    "    n_samples = data.shape[0]\n",
    "    n_test = int(n_samples*test_ratio) \n",
    "    n_val = int(n_samples*val_ratio) \n",
    "    n_train = n_samples - n_val - n_test\n",
    "    if verbose:\n",
    "        print('n_train:', n_train)\n",
    "        print('n_val:', n_val)\n",
    "        print('n_test:', n_test)\n",
    "    # get test indices\n",
    "    X = df_tvt[df_tvt[tvt_cname]=='Other'].index.values\n",
    "    y = df_tvt[df_tvt[tvt_cname]=='Other'].Label.values\n",
    "    X_train, X_test, _, _ = train_test_split(\n",
    "        X, y, test_size=n_test, shuffle=True, stratify=y, random_state=seed)\n",
    "    df_tvt.loc[X_test, tvt_cname] = 'test'\n",
    "    # get val indices\n",
    "    X = df_tvt[df_tvt[tvt_cname]=='Other'].index.values\n",
    "    y = df_tvt[df_tvt[tvt_cname]=='Other'].Label.values\n",
    "    X_train, X_val, _, _ = train_test_split(\n",
    "        X, y, test_size=n_val, shuffle=True, stratify=y, random_state=seed)\n",
    "    df_tvt.loc[X_val, tvt_cname] = 'val'\n",
    "    df_tvt.loc[X_train, tvt_cname] = 'train'\n",
    "    return df_tvt[tvt_cname]"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Generate data set split tvt file  ps: tvt is train val test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3b8be238",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NF-BoT-IoT\n",
      "Label         0       1\n",
      "Label_tvt              \n",
      "test       2772  117248\n",
      "train      8315  351745\n",
      "val        2772  117248\n",
      "Attack      Benign   DDoS    DoS  Reconnaissance  Theft\n",
      "Attack_tvt                                             \n",
      "test          2772  11236  11217           94436    359\n",
      "train         8315  34102  34330          282111   1202\n",
      "val           2772  11506  11286           94108    348\n",
      "\n",
      "\n",
      "NF-UNSW-NB15-v2\n",
      "Label            0      1\n",
      "Label_tvt                \n",
      "test        459044  19011\n",
      "train      1377134  57031\n",
      "val         459044  19011\n",
      "Attack      Analysis  Backdoor   Benign   DoS  Exploits  Fuzzers  Generic  \\\n",
      "Attack_tvt                                                                  \n",
      "test             496       442   459044  1143      6379     4313     3305   \n",
      "train           1372      1294  1377134  3503     18892    13466     9867   \n",
      "val              431       433   459044  1148      6280     4531     3388   \n",
      "\n",
      "Attack      Reconnaissance  Shellcode  Worms  \n",
      "Attack_tvt                                    \n",
      "test                  2605        300     28  \n",
      "train                 7662        869    106  \n",
      "val                   2512        258     30  \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flag_save = True\n",
    "# ds_names = ['NF-BoT-IoT', 'NF-ToN-IoT', 'NF-CSE-CIC-IDS2018-v2','NF-UNSW-NB15-v2']\n",
    "ds_names = ['NF-BoT-IoT', 'NF-UNSW-NB15-v2']\n",
    "for dataset_name in ds_names:\n",
    "    print(dataset_name)\n",
    "    data = pd.read_csv(f'./datasets/{dataset_name}.csv')\n",
    "    if dataset_name == 'NF-ToN-IoT-v2':\n",
    "        data = dropdata(data)\n",
    "    data['Label_tvt'] = get_tvt(data, label_cname='Label')\n",
    "    data['Attack_tvt'] = get_tvt(data, label_cname='Attack')\n",
    "    if flag_save:\n",
    "        data.to_csv( f'./datasets/{dataset_name}_tvt.csv', index=False)\n",
    "    #\n",
    "    print(data.pivot_table(index='Label_tvt', columns='Label', values='IPV4_SRC_ADDR', aggfunc='count'))\n",
    "    print(data.pivot_table(index='Attack_tvt', columns='Attack', values='IPV4_SRC_ADDR', aggfunc='count'))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Generate a cross-validated csv file  ps: cv is cross-validation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5a931ad2",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NF-BoT-IoT\n",
      "Fold 0\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "NF-UNSW-NB15-v2\n",
      "Fold 0\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n"
     ]
    }
   ],
   "source": [
    "flag_save = True\n",
    "n_folds = 5\n",
    "tvt_ratio = (0.6, 0.2, 0.2)\n",
    "# ds_names = ['NF-BoT-IoT', 'NF-ToN-IoT', 'NF-CSE-CIC-IDS2018-v2', 'NF-UNSW-NB15-v2']\n",
    "ds_names = ['NF-BoT-IoT', 'NF-UNSW-NB15-v2']\n",
    "for dataset_name in ds_names:\n",
    "    print(dataset_name)\n",
    "    data = pd.read_csv( f'./datasets/{dataset_name}.csv')\n",
    "    if dataset_name == 'NF-ToN-IoT-v2':\n",
    "        data = dropdata(data)\n",
    "    for fold in range(n_folds):\n",
    "        print(f'Fold {fold}')\n",
    "        seed = fold + 2024\n",
    "        data[f'Label_tvt_fold_{fold}'] = get_tvt(data, label_cname='Label', tvt_ratio=tvt_ratio, seed=seed)\n",
    "        data[f'Attack_tvt_fold_{fold}'] = get_tvt(data, label_cname='Attack', tvt_ratio=tvt_ratio, seed=seed)\n",
    "    if flag_save:\n",
    "        data.to_csv( f'./datasets/{dataset_name}_cv.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a3c4ad",
   "metadata": {},
   "source": [
    "#### Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "91bf7a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_node_features(data_01, label_groups, df_nid, i_train):\n",
    "    '''\n",
    "    Extract features of a node when it is a source node and destination node.\n",
    "    Features are the (count, frequency) of all label groups.\n",
    "    '''\n",
    "    src_cnames = ['IPV4_SRC_ADDR', 'IPV4_SRC_FULL_ADDR']\n",
    "    dst_cnames = ['IPV4_DST_ADDR', 'IPV4_DST_FULL_ADDR']\n",
    "    ## \n",
    "    df_feature_list = []\n",
    "    for grp in label_groups:\n",
    "        print('Get evidence from group:', grp)\n",
    "        data_01[f'label_{grp}'] = (data_01[label_cname]==grp).astype(int)\n",
    "        ## \n",
    "        encoder01 = ce.TargetEncoder(cols=src_cnames, handle_unknown=0)\n",
    "        encoder01.fit(data_01.loc[i_train], data_01.loc[i_train, f'label_{grp}'])\n",
    "        df_src_feature01 = encoder01.transform(data_01)[['src_nid']+src_cnames].drop_duplicates()\n",
    "        df_src_feature01.columns = ['nid'] + [f'{fn}_ratio_{grp}' for fn in src_cnames]\n",
    "        ## \n",
    "        encoder02 = ce.count.CountEncoder(cols=src_cnames, handle_unknown=0)\n",
    "        encoder02.fit(data_01.loc[i_train], data_01.loc[i_train, f'label_{grp}'])\n",
    "        df_src_feature02 = encoder02.transform(data_01)[['src_nid']+src_cnames].drop_duplicates()\n",
    "        df_src_feature02.columns = ['nid'] + [f'{fn}_freq_{grp}' for fn in src_cnames]\n",
    "        ## \n",
    "        encoder03 = ce.TargetEncoder(cols=dst_cnames, handle_unknown=0)\n",
    "        encoder03.fit(data_01.loc[i_train], data_01.loc[i_train, f'label_{grp}'])\n",
    "        df_dst_feature03 = encoder03.transform(data_01)[['dst_nid']+dst_cnames].drop_duplicates()\n",
    "        df_dst_feature03.columns = ['nid'] + [f'{fn}_ratio_{grp}' for fn in dst_cnames]\n",
    "        ## \n",
    "        encoder04 = ce.count.CountEncoder(cols=dst_cnames, handle_unknown=0)\n",
    "        encoder04.fit(data_01.loc[i_train], data_01.loc[i_train, f'label_{grp}'])\n",
    "        df_dst_feature04 = encoder04.transform(data_01)[['dst_nid']+dst_cnames].drop_duplicates()\n",
    "        df_dst_feature04.columns = ['nid'] + [f'{fn}_freq_{grp}' for fn in dst_cnames]\n",
    "        ##\n",
    "        df_feature_list += [df_src_feature01, df_src_feature02, df_dst_feature03, df_dst_feature04]\n",
    "\n",
    "    df_node_features = df_nid.copy()\n",
    "    for tdf in df_feature_list:\n",
    "        df_node_features = df_node_features.merge(tdf, on='nid', how='left')\n",
    "    df_node_features = df_node_features.fillna(0.0)\n",
    "    nf_cnames = sorted([c for c in df_node_features.columns if c != 'nid'])\n",
    "    return df_node_features, nf_cnames\n",
    "\n",
    "def get_edge_features(data_01, cat_cols, ef_cnames, i_train):\n",
    "    encoder05 = ce.TargetEncoder(cols=cat_cols, handle_unknown=0)\n",
    "    encoder05.fit(data_01.loc[i_train], data_01.loc[i_train, 'Label'])\n",
    "    df_e_features = encoder05.transform(data_01)[ef_cnames].fillna(0.0)\n",
    "    return df_e_features, ef_cnames\n",
    "\n",
    "def normalize_features(df_node_features, nf_cnames, df_e_features, ef_cnames, i_train):\n",
    "    ##\n",
    "    scaler_n = StandardScaler()\n",
    "    scaler_n.fit(df_node_features[nf_cnames].loc[i_train])\n",
    "    n_features = scaler_n.transform(df_node_features[nf_cnames])\n",
    "    scaler_e = StandardScaler()\n",
    "    scaler_e.fit(df_e_features[ef_cnames].loc[i_train])\n",
    "\n",
    "    e_features = scaler_e.transform(df_e_features)\n",
    "    return n_features, e_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "07ffbdb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def preprocess_data(data, label_cname='Label', tvt_cname='Label_tvt', cat_cols=[], ef_cnames=[]):\n",
    "    '''\n",
    "    Extract graph data:\n",
    "        - node_features: [num_nodes, num_node_features]\n",
    "        - edge_index: [2, num_edges]\n",
    "        - edge_attr: [num_edges, num_edge_features]\n",
    "        - edge_label: [num_edges, 1]\n",
    "    '''\n",
    "\n",
    "    data['IPV4_SRC_FULL_ADDR'] = data['IPV4_SRC_ADDR'].astype(str) + ':' + data['L4_SRC_PORT'].astype(str)\n",
    "    data['IPV4_DST_FULL_ADDR'] = data['IPV4_DST_ADDR'].astype(str) + ':' + data['L4_DST_PORT'].astype(str)\n",
    "    label_groups = sorted(data[label_cname].unique().tolist())\n",
    "    if len(cat_cols) == 0:\n",
    "        cat_cols = ['TCP_FLAGS','L7_PROTO','PROTOCOL']\n",
    "        ef_cnames = [\n",
    "            'FLOW_DURATION_MILLISECONDS',\n",
    "            'IN_BYTES',\n",
    "            'IN_PKTS',\n",
    "            'L7_PROTO',\n",
    "            'OUT_BYTES',\n",
    "            'OUT_PKTS',\n",
    "            'PROTOCOL',\n",
    "            'TCP_FLAGS',\n",
    "        ]\n",
    "\n",
    "    nodes = sorted(set(data['IPV4_SRC_FULL_ADDR'].unique().tolist() + data['IPV4_DST_FULL_ADDR'].unique().tolist()))\n",
    "    node2nid = {j:i for i,j in enumerate(nodes)}\n",
    "    data['src_nid'] = data['IPV4_SRC_FULL_ADDR'].map(node2nid)\n",
    "    data['dst_nid'] = data['IPV4_DST_FULL_ADDR'].map(node2nid)\n",
    "    data_01 = data.copy()\n",
    "    i_train = (data_01[tvt_cname]!='test')\n",
    "    df_nid = pd.DataFrame({'nid': node2nid.values()})\n",
    "    \n",
    "    # 1. Get node features\n",
    "    print('Get node features')\n",
    "    print(f'label_groups ====  {label_groups} ,label_groups[1:]====  {label_groups[1:]}')\n",
    "    df_node_features, nf_cnames = get_node_features(data_01, label_groups[1:], df_nid, i_train)\n",
    "    \n",
    "    # 2. Get edge features\n",
    "    print('Get edge features')\n",
    "    df_e_features, ef_cnames = get_edge_features(data_01, cat_cols, ef_cnames, i_train)\n",
    "    ### [HOTFIX] for overflow error in 'NF-CSE-CIC-IDS2018-v2' dataset\n",
    "    for f_name in ef_cnames:\n",
    "        if df_e_features[f_name].max() > 1e300:\n",
    "            df_e_features[f_name] = df_e_features[f_name].apply(np.log1p)\n",
    "    \n",
    "    # 3. Normalize feature\n",
    "    print('Normalize features')\n",
    "    n_features, e_features = normalize_features(df_node_features, nf_cnames, df_e_features, ef_cnames, i_train)\n",
    "    \n",
    "    # 4. Get edge indices\n",
    "    print('Get edge indices')\n",
    "    src_idx = data_01['src_nid'].values.tolist()\n",
    "    dst_idx = data_01['dst_nid'].values.tolist()\n",
    "    edge_index = np.array([src_idx, dst_idx])\n",
    "\n",
    "    # 5. Get edge label\n",
    "    print('Get edge label')\n",
    "    label2idx = {j:i for i,j in enumerate(label_groups)}\n",
    "    print(label2idx)\n",
    "    edge_label = data_01[label_cname].map(label2idx).values\n",
    "    \n",
    "    # 6. Get tvt\n",
    "    print('Get tvt')\n",
    "    tvt = data_01[tvt_cname].values\n",
    "\n",
    "    return n_features, e_features, edge_index, edge_label, tvt, label2idx"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Preprocessing data group 0 - without cross-validation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3157beee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 600100\n",
      "Get node features\n",
      "label_groups ====  [0, 1] ,label_groups[1:]====  [1]\n",
      "Get evidence from group: 1\n",
      "Get edge features\n",
      "Normalize features\n",
      "Get edge indices\n",
      "Get edge label\n",
      "{0: 0, 1: 1}\n",
      "Get tvt\n",
      "(77177, 8) (600100, 8) (2, 600100) (600100,) 600100\n",
      "./datasets/NF-BoT-IoT_graph_binary.pkl\n"
     ]
    }
   ],
   "source": [
    "flag_save = True\n",
    "# dataset_names = ['NF-BoT-IoT', 'NF-ToN-IoT']\n",
    "dataset_names = ['NF-BoT-IoT']\n",
    "# labels = ['Label', 'Attack']\n",
    "labels = [ 'Label']\n",
    "for dataset_name in dataset_names:\n",
    "    for label_cname in labels:\n",
    "        data = pd.read_csv( f'./datasets/{dataset_name}_tvt.csv')\n",
    "        print('Number of samples:', data.shape[0])\n",
    "        n_features, e_features, edge_index, edge_label, tvt, label2idx = preprocess_data(\n",
    "            data, label_cname=label_cname, tvt_cname=f'{label_cname}_tvt')\n",
    "        print(n_features.shape, e_features.shape, edge_index.shape, edge_label.shape,len(tvt))\n",
    "        g_data = {\n",
    "            'n_features': n_features, \n",
    "            'e_features': e_features, \n",
    "            'edge_index': edge_index, \n",
    "            'edge_label': edge_label,\n",
    "            'tvt': tvt, \n",
    "            'label2idx': label2idx,\n",
    "            'edge_ids': torch.arange(data.shape[0]).numpy(),  # id of edges [x,x,x]\n",
    "        }\n",
    "        if label_cname == 'Attack':\n",
    "            f_name =  f'./datasets/{dataset_name}_graph_multi.pkl'\n",
    "        else: \n",
    "            f_name =  f'./datasets/{dataset_name}_graph_binary.pkl'\n",
    "        print(f_name)\n",
    "        if flag_save:\n",
    "            pd.to_pickle(g_data, f_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Preprocessing data group 1 - without cross-validation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 2390275\n",
      "Get node features\n",
      "label_groups ====  [0, 1] ,label_groups[1:]====  [1]\n",
      "Get evidence from group: 1\n",
      "Get edge features\n",
      "Normalize features\n",
      "Get edge indices\n",
      "Get edge label\n",
      "{0: 0, 1: 1}\n",
      "Get tvt\n",
      "(1090451, 8) (2390275, 39) (2, 2390275) (2390275,) 2390275\n",
      "./datasets/NF-UNSW-NB15-v2_graph_binary.pkl\n"
     ]
    }
   ],
   "source": [
    "flag_save = True\n",
    "cat_cols = [\n",
    "    'TCP_FLAGS','L7_PROTO','PROTOCOL',\n",
    "    'CLIENT_TCP_FLAGS','SERVER_TCP_FLAGS','ICMP_TYPE',\n",
    "    'ICMP_IPV4_TYPE','DNS_QUERY_ID','DNS_QUERY_TYPE',\n",
    "    'FTP_COMMAND_RET_CODE',\n",
    "]\n",
    "ef_cnames = [\n",
    "    'PROTOCOL', 'L7_PROTO', 'IN_BYTES', 'IN_PKTS', 'OUT_BYTES', 'OUT_PKTS',\n",
    "    'TCP_FLAGS', 'CLIENT_TCP_FLAGS', 'SERVER_TCP_FLAGS',\n",
    "    'FLOW_DURATION_MILLISECONDS', 'DURATION_IN', 'DURATION_OUT', 'MIN_TTL',\n",
    "    'MAX_TTL', 'LONGEST_FLOW_PKT', 'SHORTEST_FLOW_PKT', 'MIN_IP_PKT_LEN',\n",
    "    'MAX_IP_PKT_LEN', 'SRC_TO_DST_SECOND_BYTES', 'DST_TO_SRC_SECOND_BYTES',\n",
    "    'RETRANSMITTED_IN_BYTES', 'RETRANSMITTED_IN_PKTS',\n",
    "    'RETRANSMITTED_OUT_BYTES', 'RETRANSMITTED_OUT_PKTS',\n",
    "    'SRC_TO_DST_AVG_THROUGHPUT', 'DST_TO_SRC_AVG_THROUGHPUT',\n",
    "    'NUM_PKTS_UP_TO_128_BYTES', 'NUM_PKTS_128_TO_256_BYTES',\n",
    "    'NUM_PKTS_256_TO_512_BYTES', 'NUM_PKTS_512_TO_1024_BYTES',\n",
    "    'NUM_PKTS_1024_TO_1514_BYTES', 'TCP_WIN_MAX_IN', 'TCP_WIN_MAX_OUT',\n",
    "    'ICMP_TYPE', 'ICMP_IPV4_TYPE', 'DNS_QUERY_ID', 'DNS_QUERY_TYPE',\n",
    "    'DNS_TTL_ANSWER', 'FTP_COMMAND_RET_CODE'\n",
    "]\n",
    "# dataset_names = ['NF-CSE-CIC-IDS2018-v2', 'NF-UNSW-NB15-v2']\n",
    "dataset_names = ['NF-UNSW-NB15-v2']\n",
    "# labels = ['Label', 'Attack']\n",
    "labels = ['Label']\n",
    "for dataset_name in dataset_names:\n",
    "    for label_cname in labels:\n",
    "        data = pd.read_csv( f'./datasets/{dataset_name}_tvt.csv')\n",
    "        print('Number of samples:', data.shape[0])\n",
    "        n_features, e_features, edge_index, edge_label, tvt, label2idx = preprocess_data(\n",
    "            data, label_cname=label_cname, tvt_cname=f'{label_cname}_tvt',cat_cols=cat_cols,ef_cnames=ef_cnames)\n",
    "        print(n_features.shape, e_features.shape, edge_index.shape, edge_label.shape,len(tvt))\n",
    "        g_data = {\n",
    "            'n_features': n_features,\n",
    "            'e_features': e_features,\n",
    "            'edge_index': edge_index,\n",
    "            'edge_label': edge_label,\n",
    "            'tvt': tvt,\n",
    "            'label2idx': label2idx,\n",
    "            'edge_ids': torch.arange(data.shape[0]).numpy(),  # id of edges [x,x,x]\n",
    "        }\n",
    "        if label_cname == 'Attack':\n",
    "            f_name =  f'./datasets/{dataset_name}_graph_multi.pkl'\n",
    "        else:\n",
    "            f_name =  f'./datasets/{dataset_name}_graph_binary.pkl'\n",
    "        print(f_name)\n",
    "        if flag_save:\n",
    "            pd.to_pickle(g_data, f_name)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Preprocessing data group 0 - with cross-validation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a5fc0415",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 600100\n",
      "Fold 0\n",
      "Get node features\n",
      "label_groups ====  [0, 1] ,label_groups[1:]====  [1]\n",
      "Get evidence from group: 1\n",
      "Get edge features\n",
      "Normalize features\n",
      "Get edge indices\n",
      "Get edge label\n",
      "{0: 0, 1: 1}\n",
      "Get tvt\n",
      "(77177, 8) (600100, 8) (2, 600100) (600100,) 600100\n",
      "./datasets/NF-BoT-IoT_cv0_graph_binary.pkl\n",
      "\n",
      "\n",
      "Fold 1\n",
      "Get node features\n",
      "label_groups ====  [0, 1] ,label_groups[1:]====  [1]\n",
      "Get evidence from group: 1\n",
      "Get edge features\n",
      "Normalize features\n",
      "Get edge indices\n",
      "Get edge label\n",
      "{0: 0, 1: 1}\n",
      "Get tvt\n",
      "(77177, 8) (600100, 8) (2, 600100) (600100,) 600100\n",
      "./datasets/NF-BoT-IoT_cv1_graph_binary.pkl\n",
      "\n",
      "\n",
      "Fold 2\n",
      "Get node features\n",
      "label_groups ====  [0, 1] ,label_groups[1:]====  [1]\n",
      "Get evidence from group: 1\n",
      "Get edge features\n",
      "Normalize features\n",
      "Get edge indices\n",
      "Get edge label\n",
      "{0: 0, 1: 1}\n",
      "Get tvt\n",
      "(77177, 8) (600100, 8) (2, 600100) (600100,) 600100\n",
      "./datasets/NF-BoT-IoT_cv2_graph_binary.pkl\n",
      "\n",
      "\n",
      "Fold 3\n",
      "Get node features\n",
      "label_groups ====  [0, 1] ,label_groups[1:]====  [1]\n",
      "Get evidence from group: 1\n",
      "Get edge features\n",
      "Normalize features\n",
      "Get edge indices\n",
      "Get edge label\n",
      "{0: 0, 1: 1}\n",
      "Get tvt\n",
      "(77177, 8) (600100, 8) (2, 600100) (600100,) 600100\n",
      "./datasets/NF-BoT-IoT_cv3_graph_binary.pkl\n",
      "\n",
      "\n",
      "Fold 4\n",
      "Get node features\n",
      "label_groups ====  [0, 1] ,label_groups[1:]====  [1]\n",
      "Get evidence from group: 1\n",
      "Get edge features\n",
      "Normalize features\n",
      "Get edge indices\n",
      "Get edge label\n",
      "{0: 0, 1: 1}\n",
      "Get tvt\n",
      "(77177, 8) (600100, 8) (2, 600100) (600100,) 600100\n",
      "./datasets/NF-BoT-IoT_cv4_graph_binary.pkl\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flag_save = True\n",
    "# dataset_names = ['NF-BoT-IoT', 'NF-ToN-IoT']\n",
    "dataset_names = ['NF-BoT-IoT']\n",
    "# labels = ['Label', 'Attack']\n",
    "labels = ['Label']\n",
    "n_folds = 5\n",
    "for dataset_name in dataset_names:\n",
    "    data = pd.read_csv( f'./datasets/{dataset_name}_cv.csv')\n",
    "    print('Number of samples:', data.shape[0])\n",
    "    \n",
    "    for label_cname in labels:\n",
    "        for fold in range(n_folds):\n",
    "            print('Fold', fold)\n",
    "            n_features, e_features, edge_index, edge_label, tvt, label2idx = preprocess_data(\n",
    "                data, label_cname=label_cname, tvt_cname=f'{label_cname}_tvt_fold_{fold}')\n",
    "            print(n_features.shape, e_features.shape, edge_index.shape, edge_label.shape, len(tvt))\n",
    "            g_data = {\n",
    "                'n_features': n_features, \n",
    "                'e_features': e_features, \n",
    "                'edge_index': edge_index, \n",
    "                'edge_label': edge_label,\n",
    "                'tvt': tvt, \n",
    "                'label2idx': label2idx,\n",
    "                'edge_ids': torch.arange(data.shape[0]).numpy(),  # id of edges [x,x,x]\n",
    "            }\n",
    "            if label_cname == 'Attack':\n",
    "                f_name =  f'./datasets/{dataset_name}_cv{fold}_graph_multi.pkl'\n",
    "            else: \n",
    "                f_name =  f'./datasets/{dataset_name}_cv{fold}_graph_binary.pkl'\n",
    "            print(f_name)\n",
    "            print('\\n')\n",
    "            if flag_save:\n",
    "                pd.to_pickle(g_data, f_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Preprocessing data group 1 - with cross-validation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1b3d2f7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 2390275\n",
      "Fold 0\n",
      "Get node features\n",
      "label_groups ====  [0, 1] ,label_groups[1:]====  [1]\n",
      "Get evidence from group: 1\n",
      "Get edge features\n",
      "Normalize features\n",
      "Get edge indices\n",
      "Get edge label\n",
      "{0: 0, 1: 1}\n",
      "Get tvt\n",
      "(1090451, 8) (2390275, 39) (2, 2390275) (2390275,) 2390275\n",
      "./datasets/NF-UNSW-NB15-v2_cv0_graph_binary.pkl\n",
      "\n",
      "\n",
      "Fold 1\n",
      "Get node features\n",
      "label_groups ====  [0, 1] ,label_groups[1:]====  [1]\n",
      "Get evidence from group: 1\n",
      "Get edge features\n",
      "Normalize features\n",
      "Get edge indices\n",
      "Get edge label\n",
      "{0: 0, 1: 1}\n",
      "Get tvt\n",
      "(1090451, 8) (2390275, 39) (2, 2390275) (2390275,) 2390275\n",
      "./datasets/NF-UNSW-NB15-v2_cv1_graph_binary.pkl\n",
      "\n",
      "\n",
      "Fold 2\n",
      "Get node features\n",
      "label_groups ====  [0, 1] ,label_groups[1:]====  [1]\n",
      "Get evidence from group: 1\n",
      "Get edge features\n",
      "Normalize features\n",
      "Get edge indices\n",
      "Get edge label\n",
      "{0: 0, 1: 1}\n",
      "Get tvt\n",
      "(1090451, 8) (2390275, 39) (2, 2390275) (2390275,) 2390275\n",
      "./datasets/NF-UNSW-NB15-v2_cv2_graph_binary.pkl\n",
      "\n",
      "\n",
      "Fold 3\n",
      "Get node features\n",
      "label_groups ====  [0, 1] ,label_groups[1:]====  [1]\n",
      "Get evidence from group: 1\n",
      "Get edge features\n",
      "Normalize features\n",
      "Get edge indices\n",
      "Get edge label\n",
      "{0: 0, 1: 1}\n",
      "Get tvt\n",
      "(1090451, 8) (2390275, 39) (2, 2390275) (2390275,) 2390275\n",
      "./datasets/NF-UNSW-NB15-v2_cv3_graph_binary.pkl\n",
      "\n",
      "\n",
      "Fold 4\n",
      "Get node features\n",
      "label_groups ====  [0, 1] ,label_groups[1:]====  [1]\n",
      "Get evidence from group: 1\n",
      "Get edge features\n",
      "Normalize features\n",
      "Get edge indices\n",
      "Get edge label\n",
      "{0: 0, 1: 1}\n",
      "Get tvt\n",
      "(1090451, 8) (2390275, 39) (2, 2390275) (2390275,) 2390275\n",
      "./datasets/NF-UNSW-NB15-v2_cv4_graph_binary.pkl\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flag_save = True\n",
    "# dataset_names = ['NF-CSE-CIC-IDS2018-v2', 'NF-UNSW-NB15-v2']\n",
    "dataset_names = ['NF-UNSW-NB15-v2']\n",
    "# labels = ['Label', 'Attack']\n",
    "labels = ['Label']\n",
    "n_folds = 5\n",
    "cat_cols = [\n",
    "    'TCP_FLAGS','L7_PROTO','PROTOCOL',\n",
    "    'CLIENT_TCP_FLAGS','SERVER_TCP_FLAGS','ICMP_TYPE',\n",
    "    'ICMP_IPV4_TYPE','DNS_QUERY_ID','DNS_QUERY_TYPE',\n",
    "    'FTP_COMMAND_RET_CODE',\n",
    "]\n",
    "ef_cnames = [\n",
    "    'PROTOCOL', 'L7_PROTO', 'IN_BYTES', 'IN_PKTS', 'OUT_BYTES', 'OUT_PKTS',\n",
    "    'TCP_FLAGS', 'CLIENT_TCP_FLAGS', 'SERVER_TCP_FLAGS',\n",
    "    'FLOW_DURATION_MILLISECONDS', 'DURATION_IN', 'DURATION_OUT', 'MIN_TTL',\n",
    "    'MAX_TTL', 'LONGEST_FLOW_PKT', 'SHORTEST_FLOW_PKT', 'MIN_IP_PKT_LEN',\n",
    "    'MAX_IP_PKT_LEN', 'SRC_TO_DST_SECOND_BYTES', 'DST_TO_SRC_SECOND_BYTES',\n",
    "    'RETRANSMITTED_IN_BYTES', 'RETRANSMITTED_IN_PKTS',\n",
    "    'RETRANSMITTED_OUT_BYTES', 'RETRANSMITTED_OUT_PKTS',\n",
    "    'SRC_TO_DST_AVG_THROUGHPUT', 'DST_TO_SRC_AVG_THROUGHPUT',\n",
    "    'NUM_PKTS_UP_TO_128_BYTES', 'NUM_PKTS_128_TO_256_BYTES',\n",
    "    'NUM_PKTS_256_TO_512_BYTES', 'NUM_PKTS_512_TO_1024_BYTES',\n",
    "    'NUM_PKTS_1024_TO_1514_BYTES', 'TCP_WIN_MAX_IN', 'TCP_WIN_MAX_OUT',\n",
    "    'ICMP_TYPE', 'ICMP_IPV4_TYPE', 'DNS_QUERY_ID', 'DNS_QUERY_TYPE',\n",
    "    'DNS_TTL_ANSWER', 'FTP_COMMAND_RET_CODE'\n",
    "]\n",
    "for dataset_name in dataset_names:\n",
    "    data = pd.read_csv( f'./datasets/{dataset_name}_cv.csv')\n",
    "    print('Number of samples:', data.shape[0])\n",
    "    for label_cname in labels:\n",
    "        for fold in range(0,n_folds):\n",
    "            print('Fold', fold)\n",
    "            n_features, e_features, edge_index, edge_label, tvt, label2idx = preprocess_data(\n",
    "                data, \n",
    "                label_cname=label_cname, \n",
    "                tvt_cname=f'{label_cname}_tvt_fold_{fold}',\n",
    "                cat_cols=cat_cols,\n",
    "                ef_cnames=ef_cnames,\n",
    "            )\n",
    "            print(n_features.shape, e_features.shape, edge_index.shape, edge_label.shape, len(tvt))\n",
    "            g_data = {\n",
    "                'n_features': n_features, \n",
    "                'e_features': e_features, \n",
    "                'edge_index': edge_index, \n",
    "                'edge_label': edge_label,\n",
    "                'tvt': tvt, \n",
    "                'label2idx': label2idx,\n",
    "                'edge_ids': torch.arange(data.shape[0]).numpy(),  # id of edges [x,x,x]\n",
    "            }\n",
    "            if label_cname == 'Attack':\n",
    "                f_name =  f'./datasets/{dataset_name}_cv{fold}_graph_multi.pkl'\n",
    "            else: \n",
    "                f_name =  f'./datasets/{dataset_name}_cv{fold}_graph_binary.pkl'\n",
    "            print(f_name)\n",
    "            print('\\n')\n",
    "            if flag_save:\n",
    "                pd.to_pickle(g_data, f_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332c64a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
